\chapter{Determinants}
\section{Characterization of the Determinant}
\begin{definition}
  \label{def:multilinear}
  A function $\delta: F^{n \times n} \to F$ is \emph{$n$-linear} if
  \begin{equation*}
    \delta(A) = k\delta(B) + \delta(C)
  \end{equation*}
  holds for any matrices $A, B, C \in F^{n \times n}$ satisfying the following
  properties for any $i \in \{1, \dots, n\}$ and for any $k \in F$.
  \begin{itemize}
    \item The $j$th rows of $A, B$ and $C$ are identical for each
    $j \in \{1, \dots, n\} \setminus \{i\}$.
    \item The $i$th row of $A$ is the sum of the $i$th row of $B$ multiplied by
    $k$ and the $i$th row of $C$.
  \end{itemize}
\end{definition}

\begin{definition}
  An $n$-linear function $\delta: F^{n \times n} \to F$ is \emph{alternating}
  if
  \begin{equation*}
    \delta(A) = 0_F
  \end{equation*}
  holds for any matrix $A \in F^{n \times n}$ that has two identical rows.
\end{definition}

\begin{proposition}
  Let $\delta: F^{n \times n} \to F$ be an alternating $n$-linear function
  and let $A \in F^{n \times n}$.
  Then the following statements are true.
  \begin{enumerate}
    \item If $E_1 \in F^{n \times n}$ is an elementary matrix of type 1,
    then $\delta(E_1A) = -\delta(A)$.
    \item If $E_2 \in F^{n \times n}$ is an elementary matrix of type 2
    obtained by multiplying one row of $I_n$ by scalar $k \in F$,
    then $\delta(E_2A) = k\delta(A)$.
    \item If $E_3 \in F^{n \times n}$ is an elementary matrix of type 3,
    then $\delta(E_3A) = \delta(A)$.
  \end{enumerate}
\end{proposition}
\begin{proof}
  Let $\row(A) = (x_1, \dots, x_n)$.
  \begin{enumerate}
    \item Let $E_1$ be obtained from $I_n$ by interchanging the $p$th row and
    the $q$th row with $p < q$.
    Then we have
    \begin{align*}
      0_F
      &=
      \delta
      \begin{pmatrix}
        x_1 \\ \vdots \\ x_p + x_q \\ \vdots \\ x_p + x_q \\ \vdots \\ x_n
      \end{pmatrix}
      =
      \delta
      \begin{pmatrix}
        x_1 \\ \vdots \\ x_p \\ \vdots \\ x_p + x_q \\ \vdots \\ x_n
      \end{pmatrix}
      +
      \delta
      \begin{pmatrix}
        x_1 \\ \vdots \\ x_q \\ \vdots \\ x_p + x_q \\ \vdots \\ x_n
      \end{pmatrix} \\
      &=
      \delta
      \begin{pmatrix}
        x_1 \\ \vdots \\ x_p \\ \vdots \\ x_p \\ \vdots \\ x_n
      \end{pmatrix}
      +
      \delta
      \begin{pmatrix}
        x_1 \\ \vdots \\ x_p \\ \vdots \\  x_q \\ \vdots \\ x_n
      \end{pmatrix}
      +
      \delta
      \begin{pmatrix}
        x_1 \\ \vdots \\ x_q \\ \vdots \\ x_p \\ \vdots \\ x_n
      \end{pmatrix}
      +
      \delta
      \begin{pmatrix}
        x_1 \\ \vdots \\ x_q \\ \vdots \\ x_q \\ \vdots \\ x_n
      \end{pmatrix} \\
      &= 0_F + \delta(A) + \delta(E_1A) + 0_F.
    \end{align*}
    Thus, $\delta(E_1A) = -\delta(A)$.

    \item Let $E_2$ be obtained from $I_n$ by multiplying the $p$th row
    by some scalar $k$.
    Then we have
    \begin{equation*}
      \delta(E_2A)
      = \delta
      \begin{pmatrix}
        x_1 \\ \vdots \\ kx_p \\ \vdots \\ x_n
      \end{pmatrix}
      = k\delta
      \begin{pmatrix}
        x_1 \\ \vdots \\ x_p \\ \vdots \\ x_n
      \end{pmatrix}
      = k\delta(A).
    \end{equation*}

    \item Let $E_3$ be obtained from $I_n$ by adding the $p$th row multiplied
    by some scalar $k$ to the $q$th row.
    If $p < q$, then we have
    \begin{equation*}
      \delta(E_3A)
      =
      \delta
      \begin{pmatrix}
        x_1 \\ \vdots \\ x_p \\ \vdots \\ kx_p + x_q \\ \vdots \\ x_n
      \end{pmatrix}
      =
      k\delta
      \begin{pmatrix}
        x_1 \\ \vdots \\ x_p \\ \vdots \\ x_p \\ \vdots \\ x_n
      \end{pmatrix}
      +
      \delta
      \begin{pmatrix}
        x_1 \\ \vdots \\ x_p \\ \vdots \\ x_q \\ \vdots \\ x_n
      \end{pmatrix}
      = k0_F + \delta(A)
      = \delta(A).
    \end{equation*}
    The case that $q < p$ can be proved similarly.
    \qedhere
  \end{enumerate}
\end{proof}

\begin{theorem}
  \label{thm:zero-determinant}
  Let $\delta: F^{n \times n} \to F$ be an alternating $n$-linear function
  and let $A \in F^{n \times n}$.
  If $\rank(A) < n$, then $\delta(A) = 0_F$.
\end{theorem}
\begin{proof}
  Since
  \begin{equation*}
    \dim(\spn(\row(A))) = \rank(A^t) = \rank(A) < n,
  \end{equation*}
  the rows of $A$ is not a spanning set of $F^n$, and thus is linearly
  dependent, implying that there exists a row which is a linear combination of
  the other rows.

  Therefore, $A$ can be transformed into a matrix $B$ that has two identical
  rows by a finite number of elementary row operations.
  It follows that
  \begin{equation*}
    \delta(A) = \delta(E_p \cdots E_1A) = \delta(B) = 0_F,
  \end{equation*}
  where $E_1, \dots, E_p \in F^{n \times n}$ are elementary matrices.
\end{proof}

\begin{theorem}
  \label{thm:determinant-multiplication}
  Let $\delta: F^{n \times n} \to F$ be an alternating $n$-linear function
  such that $\delta(I_n) = 1_F$.
  Then for any $A, B \in F^{m \times n}$, we have
  \begin{equation*}
    \delta(AB) = \delta(A)\delta(B).
  \end{equation*}
\end{theorem}
\begin{proof}
  First, suppose that $\rank(A) < n$.
  Then we have $\rank(AB) < n$.
  Thus,
  \begin{equation*}
    \delta(AB) = 0_F = \delta(A)\delta(B).
  \end{equation*}
  Now suppose that $\rank(A) = n$.
  That is, $A$ is invertible, and thus $A = E_k \cdots E_1$ for some elementary
  matrices $E_1, \dots, E_k \in F^{n \times n}$.
  Then we have
  \begin{align*}
    \delta(AB)
    &= \delta(E_k \cdots E_1B) \\
    &= \delta(E_k) \cdots \delta(E_1)\delta(B) \\
    &= \delta(E_k) \cdots \delta(E_1)\delta(I_n)\delta(B)
       \tag{$\delta(I_n) = 1_F$} \\
    &= \delta(E_k \cdots E_1I_n)\delta(B) \\
    &= \delta(A)\delta(B).
    \qedhere
  \end{align*}
\end{proof}

\begin{theorem}
  \label{thm:determinant-uniqueness}
  There exists a unique alternating $n$-linear function
  $\delta: F^{n \times n} \to F$ with $\delta(I_n) = 1_F$.
\end{theorem}
\begin{proof}
  Suppose that $\delta, \delta': F^{n \times n} \to F$ are alternating
  $n$-linear functions with $\delta(I_n) = 1_F = \delta'(I_n)$.
  We prove that $\delta(A) = \delta(A')$ for any $A \in F^{n \times n}$.
  If $\rank(A) < n$, then
  \begin{equation*}
    \delta(A) = 0_F = \delta'(A).
  \end{equation*}
  If $\rank(A) = n$, then $A$ is invertible, and thus
  \begin{equation*}
    A = E_p \cdots E_1
  \end{equation*}
  for some elementary matrices $E_1, \dots, E_p \in F^{n \times n}$.
  It follows that
  \begin{align*}
    \delta(A)
    &= \delta(E_p \cdots E_1I_n) \\
    &= \delta(E_p)\cdots\delta(E_1)\delta(I_n) \\
    &= \delta'(E_p)\cdots\delta'(E_1)\delta(I_n) \\
    &= \delta'(E_p \cdots E_1I_n) \\
    &= \delta'(A).
    \qedhere
  \end{align*}
\end{proof}

\begin{definition}
  The \emph{determinant} of $A \in F^{n \times n}$ is
  \begin{equation*}
    \det(A) = \delta(A),
  \end{equation*}
  where $\delta: F^{n \times n} \to F$ is the alternating $n$-linear function
  with $\delta(I_n) = 1_F$.
\end{definition}

\section{Permutations}
\begin{definition}
  \label{def:permutation}
  \leavevmode
  \begin{itemize}
    \item A function $\sigma: \{1, 2, \dots, n\} \to \{1, 2, \dots, n\}$
    is a \emph{permutation} over $\{1, 2, \dots, n\}$ if $\sigma$ is
    bijective. The set of all permutations over $\{1, 2, \dots, n\}$ is denoted
    by $S_n$.
    \item An inversion of $\sigma \in S_n$ is a pair $(i, j)$ with
    $1 \leq i < j \leq n$ and $\sigma(i) > \sigma(j)$.
    The number of inversions of $\sigma$ is denoted by $\rho(\sigma)$.
    \item The \emph{sign} of $\sigma \in S_n$ is defined by
    \begin{equation*}
      \sgn(\sigma) = (-1)^{\rho(\sigma)}.
    \end{equation*}
  \end{itemize}
\end{definition}

\begin{theorem}
  \label{thm:determinant-permutation}
  For any matrix $A \in F^{n \times n}$,
  \begin{equation*}
    \det(A)
    = \sum_{\sigma \in S_n} \sgn(\sigma) \prod_{i=1}^n A_{i, \sigma(i)}.
  \end{equation*}
\end{theorem}
\begin{proof}
  Let $\delta: F^{n \times n} \to F$ be the function
  \begin{equation*}
    \delta(A)
    = \sum_{\sigma \in S_n} \sgn(\sigma) \prod_{i=1}^n A_{i, \sigma(i)}.
  \end{equation*}
  We prove that $\delta$ is an alternating $n$-linear function with
  $\delta(I_n) = 1_F$.

  First, we show that $\delta$ is $n$-linear.
  Suppose that $A, B, C \in F^{n \times n}$ are matrices satisfying the
  following properties for any $p \in \{1, \dots, n\}$ and for any $k \in F$.
  \begin{itemize}
    \item The $i$th rows of $A, B$ and $C$ are identical for each
    $i \in \{1, \dots, n\} \setminus \{p\}$.
    \item The $p$th row of $A$ is the sum of the $p$th row of $B$ multiplied by
    $k$ and the $p$th row of $C$.
  \end{itemize}
  Then we have
  \begin{align*}
    \delta(A)
    &= \sum_{\sigma \in S_n} \sgn(\sigma) A_{p,\sigma(p)}
    \prod_{\substack{1 \leq i \leq n \\ i \neq p}} A_{i,\sigma(i)} \\
    &= \sum_{\sigma \in S_n} \sgn(\sigma) (kB_{p,\sigma(p)} + C_{p,\sigma(p)})
    \prod_{\substack{1 \leq i \leq n \\ i \neq p}} A_{i,\sigma(i)} \\
    &= k\sum_{\sigma \in S_n} \sgn(\sigma) B_{p,\sigma(p)}
    \prod_{\substack{1 \leq i \leq n \\ i \neq p}} A_{i,\sigma(i)}
    + \sum_{\sigma \in S_n} \sgn(\sigma) C_{p,\sigma(p)}
    \prod_{\substack{1 \leq i \leq n \\ i \neq p}} A_{i,\sigma(i)} \\
    &= k\sum_{\sigma \in S_n} \sgn(\sigma) B_{p,\sigma(p)}
    \prod_{\substack{1 \leq i \leq n \\ i \neq p}} B_{i,\sigma(i)}
    + \sum_{\sigma \in S_n} \sgn(\sigma) C_{p,\sigma(p)}
    \prod_{\substack{1 \leq i \leq n \\ i \neq p}} C_{i,\sigma(i)} \\
    &= k\delta(B) + \delta(C).
  \end{align*}
  Now we show that $\delta$ is alternating.
  Suppose that $D \in F^{n \times n}$ is a matrix whose $p$th row and $q$th row
  are identical with $p \neq q$.
  For each $\sigma \in S_n$, let $\sigma' \in S_n$ be the permutation that
  satisfies the following properties.
  \begin{itemize}
    \item $\sigma'(p) = \sigma(q)$ and $\sigma'(q) = \sigma(p)$.
    \item $\sigma'(i) = \sigma(i)$ for each
    $i \in \{1, \dots, n\} \setminus \{p, q\}$.
  \end{itemize}
  Then we have
  \begin{align*}
    \delta(D)
    &= \sum_{\sigma \in S_n} \sgn(\sigma)
    \prod_{1 \leq i \leq n} D_{i,\sigma(i)} \\
    &= \sum_{\substack{\sigma \in S_n \\ \sigma(p) < \sigma(q)}} \sgn(\sigma)
    \prod_{1 \leq i \leq n} D_{i,\sigma(i)}
    + \sum_{\substack{\sigma \in S_n \\ \sigma(p) > \sigma(q)}} \sgn(\sigma)
    \prod_{1 \leq i \leq n} D_{i,\sigma(i)} \\
    &= \sum_{\substack{\sigma \in S_n \\ \sigma(p) < \sigma(q)}} \sgn(\sigma)
    \prod_{1 \leq i \leq n} D_{i,\sigma(i)}
    + \sum_{\substack{\sigma \in S_n \\ \sigma(p) < \sigma(q)}} \sgn(\sigma')
    \prod_{1 \leq i \leq n} D_{i,\sigma'(i)} \\
    &= \sum_{\substack{\sigma \in S_n \\ \sigma(p) < \sigma(q)}}
    (\sgn(\sigma) + \sgn(\sigma')) \prod_{1 \leq i \leq n} D_{i,\sigma(i)} \\
    &= 0_F.
  \end{align*}
  Finally, we have
  \begin{equation*}
    \delta(I_n) = \sgn(\sigma_0) = 1_F,
  \end{equation*}
  where $\sigma_0$ is the identity permutation.
  Therefore, $\delta$ is an alternating $n$-linear function with
  $\delta(I_n) = 1_F$, and by \Cref{thm:determinant-uniqueness} we can conclude
  that it is exactly the determinant function.
\end{proof}

\section{Properties of Determinants}
\begin{theorem}
  For any $A, B \in F^{n \times n}$, we have $\det(AB) = \det(A)\det(B)$.
\end{theorem}
\begin{proof}
  Striaghtforward from \Cref{thm:determinant-multiplication}.
\end{proof}

\begin{theorem}
  If $A \in F^{n \times n}$ is invertible, then $\det(A^{-1}) =
  (\det(A))^{-1}$.
\end{theorem}
\begin{proof}
  It follows by
  \begin{equation*}
    \det(A^{-1})\det(A)
    = \det(A^{-1}A)
    = \det(I_n)
    = 1_F.
    \qedhere
  \end{equation*}
\end{proof}

\begin{definition}
  Let $A, B \in F^{n \times n}$.
  We say that $A$ and $B$ are \emph{similar}, denoted
  \begin{equation*}
    A \sim B,
  \end{equation*}
  if there is an invertible matrix $Q \in F^{n \times n}$ such that
  $B = QAQ^{-1}$.
\end{definition}

\begin{theorem}
  For any $A, B \in F^{n \times n}$, if $A \sim B$, then $\det(A) = \det(B)$.
\end{theorem}
\begin{proof}
  Suppose that $Q$ is invertible such that $B = QAQ^{-1}$.
  Then
  \begin{align*}
    \det(B)
    &= \det(QAQ^{-1}) \\
    &= \det(Q) \cdot \det(A) \cdot \det(Q^{-1}) \\
    &= \det(Q) \cdot \det(Q^{-1}) \cdot \det(A) \\
    &= \det(I_n) \cdot \det(A) \\
    &= \det(A).
    \qedhere
  \end{align*}
\end{proof}

\begin{definition}
  Let $n \geq 2$.
  For any $A \in F^{n \times n}$ and for any $i, j \in \{1, \dots, n\}$,
  let $\tilde A_{ij}$ denote the $(n-1) \times (n-1)$ matrix obtained from $A$
  by deleting the $i$th row and the $j$th column.
\end{definition}

\begin{theorem}[Laplace Expansion]
  Let $n \geq 2$.
  For any $A \in F^{n \times n}$ and $i \in \{1, \dots, n\}$, we have
  \begin{equation*}
    \det(A) = \sum_{j=1}^n A_{ij} (-1)^{i+j} \det(\tilde A_{ij}).
  \end{equation*}
\end{theorem}
\begin{proof}
  For $j \in \{1, \dots, n\}$, let $B^{(j)}$ be the matrix obtained from $A$
  by replacing its $i$th row with $e_j$.
  Note that we can turn $B^{(j)}$ into a matrix
  \begin{equation*}
    C^{(j)} =
    \begin{pmatrix}
      1 & O \\
      X & \tilde A_{ij}
    \end{pmatrix}
  \end{equation*}
  by $i-1$ row swaps and $j-1$ column swaps, where $X$ is an $(n-1) \times 1$
  matrix, and $O$ is the $1 \times (n-1)$ zero matrix.
  Thus, we have
  \begin{equation*}
    \det(B^{(j)})
    = (-1)^{(i-1)+(j-1)} \det(C^{j})
    = (-1)^{i+j} \det(\tilde A_{ij}).
  \end{equation*}
  Since $\det(\cdot)$ is $n$-linear, we have
  \begin{equation*}
    \det(A)
    = \sum_{j=1}^n A_{ij} \det(B^{(j)})
    = \sum_{j=1}^n A_{ij} (-1)^{i+j} \det(\tilde A_{ij}).
    \qedhere
  \end{equation*}
\end{proof}